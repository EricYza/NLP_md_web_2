---
title: "About Me" 
layout: page
multilingual: true
draft: false   
---

# About Me

> **Ph.D. in Computer Science & Technology · Large Language Model Researcher · Tech Blogger**
> A researcher who closes the loop from research → engineering → product → communication—turning SOTA into SOP with reproducible experiments, maintainable systems, and clear writing.

---

## Executive Summary

| Dimension   | Highlights                                                                                               | Evidence                           |
| ----------- | -------------------------------------------------------------------------------------------------------- | ---------------------------------- |
| Research    | LLM alignment (DPO/RLHF/RLAIF), reasoning & agents, trustworthy RAG, efficient training (LoRA/QLoRA/MoE) | Projects & open-source repos       |
| Engineering | Distributed training/inference, eval platform, A/B & canary releases, observability                      | System designs & iteration cadence |
| Impact      | Long-form tech blogging, internal workshops, reusable materials                                          | Readership / reuse & feedback      |
| Method      | “Eval-first, data-centric, engineering-grounded, compliance-by-design”                                   | Postmortems & metric loops         |

---

## Core Value

* **Turn SOTA into SOP**: convert new papers into executable playbooks and templates.
* **Turn models into systems**: deployable, observable, rollback-ready.
* **Turn metrics into experience**: make offline gains transfer online through trustworthy evaluation.
* **Make complexity simple**: structured prompts, code samples, and reproducible experiments.

---

## Skill Matrix

| Area                     | Subskills                                                     | Proficiency | Notes                             |
| ------------------------ | ------------------------------------------------------------- | ----------- | --------------------------------- |
| Training & Optimization  | PyTorch, DeepSpeed, FSDP, ZeRO, LoRA/QLoRA, AMP               | ★★★★★       | End-to-end build & migration      |
| Alignment & Preference   | SFT, DPO/IPO, RLHF/RLAIF, preference data generation/cleaning | ★★★★★       | Stability & difficulty control    |
| Reasoning & Agents       | CoT/ToT/GoT, function calling, tool ecosystems & planning     | ★★★★☆       | Read → Think → Search → Write     |
| RAG                      | Chunking/recall, reranking, faithful citations, vector DBs    | ★★★★☆       | Long-document & regulatory QA     |
| Evaluation & Reliability | Hallucination detection, robustness, factuality & uncertainty | ★★★★★       | Automated regression & alerts     |
| Systems                  | Distributed clusters, CI/CD, tracing/profiling/logging        | ★★★★☆       | High-velocity iterations & canary |

---

## Research Interests

* **Alignment & Feedback Learning**: steady-state training and difficulty-aware sampling for DPO/ORPO vs RLHF.
* **Reasoning & Tool Use**: from prompt design to multi-step planning and environment interaction.
* **Efficiency & Sparsity**: QLoRA, quantization/distillation, MoE routing and stability.
* **Evaluation & Safety**: factuality, hallucination mitigation, red-teaming/risk and compliance.
* **Multimodal & Long Context**: cross-modal retrieval/memory, long-document state management.

---

## Selected Projects

1. **Reasoning-First LLM (Read–Think–Search–Write loop)**

   * Boosted complex task success and interpretability via **hierarchical prompts + retrieval reranking + reward-based reordering**, reducing hallucinations.
2. **Lightweight Alignment Pipeline (Small-compute reproducible)**

   * **Preference bootstrapping → SFT → DPO** in one flow; stable convergence with RLHF-comparable results on limited budgets.
3. **Trustworthy RAG for Long Docs/Regulations**

   * **Semantic chunking + reranking + traceable citations** to tightly bind answers with sources and lower risk.
4. **Unified Evaluation & Observability Platform**

   * Academic + private business sets; **automated regression, A/B comparisons, and metric alerts**.

---

## Playbooks (Methods)

* **Data Governance**: dedupe/detox, hard-example mining, mixture-of-datasets ratio search.
* **Stable Training**: grad clipping, satellite loss metrics, warm restarts for alignment phases.
* **Trustworthy Evaluation**: scenario–capability–risk axes; align metrics with user experience.
* **Release Strategy**: canary rollout, guardrails & rollback, cold-start and cache hygiene.

---

## Publications & Writing

> Note: Two parts below. **A. Verified/Real entries (to be filled)** and **B. [Sample/Placeholder] entries** for layout only—they **do not represent real publications**. Replace them with real items when available.

### A. Verified / Real (example: to be added)

* (Add once available: authors, title, venue/journal, year, link/DOI)

### B. **[Sample/Placeholder]** (can be styled as “Under Review / Preprint [Sample]”)

| Type   | Authors          | Title                                                                                   | Venue/Journal                      | Year | Notes                                           |
| ------ | ---------------- | --------------------------------------------------------------------------------------- | ---------------------------------- | ---- | ----------------------------------------------- |
| Sample | Your Name et al. | **Direct Preference Optimization at Scale: Stabilizing Alignment with Hard-Neg Mining** | ICLR (**under review**, sample)    | 2026 | Large-scale DPO with hard-negative mining       |
| Sample | Your Name et al. | **Retrieval-First Agents: Closing the Loop for Read–Think–Search–Act**                  | NeurIPS (**under review**, sample) | 2026 | Agentic retrieval and execution loop            |
| Sample | Your Name et al. | **Trustable RAG: Calibrated Citations and Hallucination Audits**                        | TACL (**preprint**, sample)        | 2026 | Faithful citations & hallucination audits       |
| Sample | Your Name et al. | **QLoRA++: Memory-Efficient Alignment under Budget Constraints**                        | JMLR (**draft**, sample)           | 2026 | Parameter-efficient alignment under constraints |


---

## Blogging & Talks

| Format              | Topic                                         | Audience/Context                 | Deliverables                       |
| ------------------- | --------------------------------------------- | -------------------------------- | ---------------------------------- |
| Long-form Series    | LLM Alignment in Practice (data → deployment) | Mixed research/engineering teams | Tutorials, scripts, checklists     |
| Technical Checklist | Faithful RAG & Evaluation                     | Regulatory / enterprise QA       | Demo + metric reports              |
| Internal Workshop   | Distributed Training & Observability          | Platform & infra teams           | Diagnostic guides & best practices |

---

## Open Source & Community

* Contribute to training/evaluation toolchains, prompt templates, and data utilities.
* Maintain **MRR: Minimal Reproducible Reference** examples for teaching and downstream reuse.
* Mentor newcomers with roadmaps and code reviews; advocate for reproducibility and open standards.

---

## Education

* **Ph.D., Computer Science & Technology**
  Focus: LLM alignment, reasoning, and reliability, with strong systems & engineering practice.

---

## Contact

* **Email**: your.name [at] example.com
* **Blog**: yourblog.example.com
* **GitHub**: github.com/yourhandle
* **WeChat/Telegram**: available upon request

---

## Appendix

### 1) BibTeX (Sample/Placeholder)

```bibtex
@inproceedings{yourkey2026dpo,
  author = {Your Name and Coauthor, X.},
  title = {Direct Preference Optimization at Scale: Stabilizing Alignment with Hard-Neg Mining},
  booktitle = {International Conference on Learning Representations},
  year = {2026},
  note = {[Sample/Placeholder] Replace with real publication details}
}
```

### 2) KPI Dashboard (Sample/Placeholder)

| Metric             | Definition                          | Current | Target  |
| ------------------ | ----------------------------------- | ------- | ------- |
| Hallucination Rate | % of unverifiable responses         | —       | < 5%    |
| Faithfulness@K     | % answers consistent with citations | —       | > 95%   |
| Latency (p95)      | End-to-end 95th percentile          | —       | < 800ms |

---

## TL;DR

I specialize in **LLM alignment, reasoning, and reliability**—turning **SOTA into SOP, models into systems, and metrics into user experience**—and I amplify impact through **writing and open source**. Open to collaboration and knowledge transfer.
